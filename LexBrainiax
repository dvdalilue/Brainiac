#!/usr/bin/env ruby

###########################
#Enumeracion de los Tokens#
###########################

rw = Hash::new
reserved_words = %w(declare execute done read write while do if else end from at tape to true false integer boolean)

reserved_words.each do |s|
  rw[s.capitalize] = /\A#{s}\b/
end

tk = {

  'Cinta'           =>  /\A{[+-<>.,]*}/               ,      
  'ConstructorTape' =>  /\A\[[a-zA-Z_][0-9a-zA-Z_]*\]/,
  'Coma'            =>  /\A\,/                        ,      
  'Punto'           =>  /\A\./                        ,       
  'PuntoYComa'      =>  /\A\;/                        ,       
  'ParAbre'         =>  /\A\(/                        ,       
  'ParCierra'       =>  /\A\)/                        ,       
  'CorcheteAbre'    =>  /\A\[/                        ,       
  'CorcheteCierra'  =>  /\A\]/                        ,       
  'LlaveAbre'       =>  /\A\{/                        ,       
  'LlaveCierra'     =>  /\A\}/                        ,       
  'Type'            =>  /\A\:\:/                      ,       
  'Menos'           =>  /\A\-/                        ,      
  'Mas'             =>  /\A\+/                        ,      
  'Mult'            =>  /\A\*/                        ,       
  'Div'             =>  /\A\/(?![\\=])/               ,       
  'Mod'             =>  /\A\%/                        ,       
  'Conjuncion'      =>  /\A\/\\/                      ,       
  'Disyuncion'      =>  /\A\\\//                      ,       
  'Negacion'        =>  /\A\~/                        ,       
  'Menor'           =>  /\A\<(?!=)/                   ,       
  'MenorIgual'      =>  /\A\<=/                       ,       
  'Mayor'           =>  /\A\>(?!=)/                   ,       
  'MayorIgual'      =>  /\A\>=/                       ,       
  'Igual'           =>  /\A\=/                        ,       
  'Desigual'        =>  /\A\/=/                       ,       
  'Concat'          =>  /\A\&/                        ,       
  'Inspeccion'      =>  /\A\#/                        ,      
  'Asignacion'      =>  /\A\:=/                       ,     
  'Ident'           =>  /\A[a-zA-Z_][0-9a-zA-Z_]*/    ,
  'Error'           =>  /\A\W/                        ,   
  'Num'             =>  /\A\d*/                       ,

}

$tokens = rw.merge(tk)

###########################
#Declaracion de las clases#
###########################

class PhraseS

  attr_accessor :text, :line, :column

  def initialize(text, line, column)
    @text = text
    @line = line
    @column = column
  end
end

class LexicographError < PhraseS

  def to_s
    "Error: Caracter inesperado \"#{@text}\" en la fila #{@line}, columna #{@column}"
  end
end

class Token < PhraseS

  class << self
    attr_accessor :regex
  end

  def to_s
    "#{self.class.name}#{if self.class.name.eql?("TkIdent") then "(\"#{@text}\")" end}#{if self.class.name.eql?("TkNum") then "(#{@text})" end} "
  end
end

class Lexer

  def initialize(input)
    @tokens = []
    @errors = []
    @input = input
    @line = 1
    @column = 1
    @comment = 0
  end

  def lex_ignore_c(length)
    @column  += length
  end

  def lex_ignore(length)
    
    return if length.eql?0

    word = @input[0..length]
    lineas = (word + ' ').lines.to_a.length.pred
    @line += lineas
    @input = @input[length..@input.length]

    if lineas.eql?0 then
      lex_ignore_c(length)
    else
      @column = 1
    end
  end

  def tokenize(nphrase)

    nct = LexicographError
    ntt = nphrase

    if nphrase =~ /\A\$-.*/
      @comment = 1
    else
      $tokens.each { |key, value|
        if nphrase =~ value
          nct = "Tk" + "#{key}"
          ntt = $&
          break
        end
      }
    end

    if @comment == 0
      if nct == "TkError"
        nct = LexicographError
      else      
        nct = Object.const_get(nct)
      end

      newtk = nct.new(ntt,@line,@column)
      
      if newtk.is_a? LexicographError
        @errors << newtk
      else
        @tokens << newtk
        if ntt.length < nphrase.length
          lex_ignore_c(ntt.length)
          tokenize(nphrase[ntt.length..nphrase.length])
        end
      end
    end
  end

  def lex_catch

    return false if @input.eql?(nil)

    @input.match(/\A(\s|\n)*/)
    lex_ignore($&.length)
    @input.match(/\A[\w\p{punct}]*\s/)

    if $&.eql?nil
      lex_ignore(1)
    else
      mlength = $&.length
      if @comment == 0
        tokenize(@input[0..($&.length-2)])
      else
        if $& =~ /\A.*-\$/
          @comment = 0
        end
      end
      lex_ignore(mlength)
    end
  end

  def to_s
    (if @errors.empty? then @tokens else @errors end).map { |tk| puts tk.inspect }
  end
end

#######################################
#Declaracion de clases para cada token#
#######################################

$tokens.each do |id,regex|

  newclass = Class::new(Token) do

    @regex = regex
    
    def initialize(text, line, column)
      @text = text
      @line = line
      @column = column
    end
  end

  Object::const_set("Tk#{id}", newclass)

end

###############################
#Definicion del Main del Lexer#
###############################

def main

  input = File::read(ARGV[0])
  lexer = Lexer::new (input)
  goon = true

  while (goon) do
    goon = lexer.lex_catch
  end
  lexer.to_s
end

main
